{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91721,"databundleVersionId":13760552,"sourceType":"competition"}],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import Ridge\nfrom scipy.stats import rankdata\nfrom catboost import CatBoostRegressor, Pool\nimport lightgbm as lgb\nfrom xgboost import XGBRegressor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:49:30.598409Z","iopub.execute_input":"2025-10-30T22:49:30.598966Z","iopub.status.idle":"2025-10-30T22:49:30.605802Z","shell.execute_reply.started":"2025-10-30T22:49:30.598938Z","shell.execute_reply":"2025-10-30T22:49:30.604781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"SEED  = 42\nFOLDS = 5\nnp.random.seed(SEED)\n\ndef rmse(y_true, y_pred): \n    return mean_squared_error(y_true, y_pred, squared=False)\n\ndef clip01(a): \n    return np.clip(a, 0, 1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:49:33.446836Z","iopub.execute_input":"2025-10-30T22:49:33.447177Z","iopub.status.idle":"2025-10-30T22:49:33.454002Z","shell.execute_reply.started":"2025-10-30T22:49:33.447156Z","shell.execute_reply":"2025-10-30T22:49:33.452609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/playground-series-s5e10/train.csv\")\ntest  = pd.read_csv(\"/kaggle/input/playground-series-s5e10/test.csv\")\n\ny = train[\"accident_risk\"]\nX = train.drop([\"id\", \"accident_risk\"], axis=1)\nX_test = test.drop([\"id\"], axis=1)\n\nprint(\"Train shape:\", X.shape)\nprint(\"Test shape:\", X_test.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:49:45.094107Z","iopub.execute_input":"2025-10-30T22:49:45.095316Z","iopub.status.idle":"2025-10-30T22:49:46.393474Z","shell.execute_reply.started":"2025-10-30T22:49:45.095231Z","shell.execute_reply":"2025-10-30T22:49:46.392668Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nMissing values (train):\\n\", X.isnull().sum()[X.isnull().sum() > 0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:49:57.399115Z","iopub.execute_input":"2025-10-30T22:49:57.399467Z","iopub.status.idle":"2025-10-30T22:49:57.561338Z","shell.execute_reply.started":"2025-10-30T22:49:57.399441Z","shell.execute_reply":"2025-10-30T22:49:57.559859Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sns.histplot(y, bins=40, kde=True)\nplt.title(\"Distribution of Accident Risk\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:50:09.419828Z","iopub.execute_input":"2025-10-30T22:50:09.420134Z","iopub.status.idle":"2025-10-30T22:50:11.322200Z","shell.execute_reply.started":"2025-10-30T22:50:09.420113Z","shell.execute_reply":"2025-10-30T22:50:11.321207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_cols = X.select_dtypes(include=[\"float64\", \"int64\"]).columns\nif len(num_cols) > 0:\n    plt.figure(figsize=(8,6))\n    sns.heatmap(pd.concat([X[num_cols], y], axis=1).corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n    plt.title(\"Correlation Heatmap (Numeric Features)\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:50:24.593871Z","iopub.execute_input":"2025-10-30T22:50:24.594249Z","iopub.status.idle":"2025-10-30T22:50:24.866063Z","shell.execute_reply.started":"2025-10-30T22:50:24.594226Z","shell.execute_reply":"2025-10-30T22:50:24.865171Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cat_cols = X.select_dtypes(include=[\"object\", \"bool\", \"category\"]).columns.tolist()\nfor c in cat_cols:\n    X[c] = X[c].astype(str)\n    X_test[c] = X_test[c].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:50:38.094554Z","iopub.execute_input":"2025-10-30T22:50:38.095440Z","iopub.status.idle":"2025-10-30T22:50:38.546639Z","shell.execute_reply.started":"2025-10-30T22:50:38.095409Z","shell.execute_reply":"2025-10-30T22:50:38.545582Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for col in X.columns:\n    if col not in cat_cols:\n        X[col] = pd.to_numeric(X[col], errors=\"ignore\")\n        X_test[col] = pd.to_numeric(X_test[col], errors=\"ignore\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:50:47.797958Z","iopub.execute_input":"2025-10-30T22:50:47.798275Z","iopub.status.idle":"2025-10-30T22:50:47.810544Z","shell.execute_reply.started":"2025-10-30T22:50:47.798256Z","shell.execute_reply":"2025-10-30T22:50:47.809533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if \"road_type\" in X.columns and \"lighting\" in X.columns:\n    X[\"road_lighting\"] = X[\"road_type\"] + \"_\" + X[\"lighting\"]\n    X_test[\"road_lighting\"] = X_test[\"road_type\"] + \"_\" + X_test[\"lighting\"]\n\n\nbad_weather = {\"rain\", \"snow\", \"fog\", \"storm\"}\nif \"weather\" in X.columns:\n    X[\"bad_weather_flag\"] = X[\"weather\"].str.lower().isin(bad_weather).astype(int)\n    X_test[\"bad_weather_flag\"] = X_test[\"weather\"].str.lower().isin(bad_weather).astype(int)\n\nif set([\"holiday\",\"school_season\"]).issubset(X.columns):\n    X[\"holiday_school_flag\"] = ((X[\"holiday\"] == \"True\") | (X[\"school_season\"] == \"True\")).astype(int)\n    X_test[\"holiday_school_flag\"] = ((X_test[\"holiday\"] == \"True\") | (X_test[\"school_season\"] == \"True\")).astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:51:07.001594Z","iopub.execute_input":"2025-10-30T22:51:07.001987Z","iopub.status.idle":"2025-10-30T22:51:07.329024Z","shell.execute_reply.started":"2025-10-30T22:51:07.001963Z","shell.execute_reply":"2025-10-30T22:51:07.327518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def _is_floatable(v):\n    try:\n        float(v); return True\n    except:\n        return False\n\nif \"time_of_day\" in X.columns:\n    numeric_like_time = X[\"time_of_day\"].map(_is_floatable).mean() > 0.9\n    if numeric_like_time:\n        X[\"time_of_day\"] = X[\"time_of_day\"].astype(float)\n        X_test[\"time_of_day\"] = X_test[\"time_of_day\"].astype(float)\n        X[\"time_sin\"] = np.sin(2 * np.pi * X[\"time_of_day\"]/24)\n        X[\"time_cos\"] = np.cos(2 * np.pi * X[\"time_of_day\"]/24)\n        X_test[\"time_sin\"] = np.sin(2 * np.pi * X_test[\"time_of_day\"]/24)\n        X_test[\"time_cos\"] = np.cos(2 * np.pi * X_test[\"time_of_day\"]/24)\n        X[\"rush_hour_flag\"] = ((X[\"time_of_day\"].between(7, 9)) | (X[\"time_of_day\"].between(16, 19))).astype(int)\n        X_test[\"rush_hour_flag\"] = ((X_test[\"time_of_day\"].between(7, 9)) | (X_test[\"time_of_day\"].between(16, 19))).astype(int)\n\n\nif \"speed_limit\" in X.columns and \"weather\" in X.columns:\n    try:\n        X[\"speed_limit\"] = X[\"speed_limit\"].astype(float)\n        X_test[\"speed_limit\"] = X_test[\"speed_limit\"].astype(float)\n        bw_tr = X[\"weather\"].str.lower().isin(bad_weather).astype(int)\n        bw_te = X_test[\"weather\"].str.lower().isin(bad_weather).astype(int)\n        X[\"weather_risk\"] = X[\"speed_limit\"] * bw_tr\n        X_test[\"weather_risk\"] = X_test[\"speed_limit\"] * bw_te\n    except:\n        pass\n\n\nif set([\"road_type\",\"weather\",\"lighting\"]).issubset(X.columns):\n    X[\"danger_combo\"] = (X[\"road_type\"] + \"_\" + X[\"weather\"] + \"_\" + X[\"lighting\"])\n    X_test[\"danger_combo\"] = (X_test[\"road_type\"] + \"_\" + X_test[\"weather\"] + \"_\" + X_test[\"lighting\"])\n\n\ncat_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\nprint(\"Categorical columns used:\", cat_cols)\nprint(\"Total features after FE:\", X.shape[1])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:51:40.945684Z","iopub.execute_input":"2025-10-30T22:51:40.946140Z","iopub.status.idle":"2025-10-30T22:51:41.845241Z","shell.execute_reply.started":"2025-10-30T22:51:40.946112Z","shell.execute_reply":"2025-10-30T22:51:41.843380Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ncat_idx = [X.columns.get_loc(c) for c in cat_cols]\n\ncb_params = dict(\n    iterations=10000,\n    learning_rate=0.018,\n    depth=9,\n    l2_leaf_reg=7,\n    bagging_temperature=0.4,\n    random_strength=0.9,\n    loss_function=\"RMSE\",\n    random_seed=SEED,\n    verbose=500,\n    early_stopping_rounds=500\n)\n\noof_cb = np.zeros(len(X))\ntest_pred_folds_cb = []\n\nfor fold, (tr_idx, va_idx) in enumerate(kf.split(X, y), 1):\n    X_tr, y_tr = X.iloc[tr_idx], y.iloc[tr_idx]\n    X_va, y_va = X.iloc[va_idx], y.iloc[va_idx]\n\n    train_pool = Pool(X_tr, y_tr, cat_features=cat_idx)\n    valid_pool = Pool(X_va, y_va, cat_features=cat_idx)\n    test_pool  = Pool(X_test,      cat_features=cat_idx)\n\n    model_cb = CatBoostRegressor(**cb_params)\n    model_cb.fit(train_pool, eval_set=valid_pool)\n\n    oof_cb[va_idx] = model_cb.predict(valid_pool)\n    print(f\"[CatBoost Fold {fold}] RMSE: {rmse(y_va, oof_cb[va_idx]):.5f}\")\n\n    test_pred_folds_cb.append(model_cb.predict(test_pool))\n\noof_cb = clip01(oof_cb)\ncv_rmse_cb = rmse(y, oof_cb)\nprint(f\"\\n[CatBoost] OOF CV RMSE: {cv_rmse_cb:.5f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-30T22:52:58.510616Z","iopub.execute_input":"2025-10-30T22:52:58.511848Z","iopub.status.idle":"2025-10-31T01:16:39.007622Z","shell.execute_reply.started":"2025-10-30T22:52:58.511806Z","shell.execute_reply":"2025-10-31T01:16:39.006762Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nRunning LightGBM CV...\")\n\nX_lgb = X.copy()\nX_test_lgb = X_test.copy()\nfor c in cat_cols:\n    X_lgb[c] = X_lgb[c].astype(\"category\")\n    X_test_lgb[c] = X_test_lgb[c].astype(\"category\")\n\nlgb_params = dict(\n    objective=\"regression\",\n    metric=\"rmse\",\n    learning_rate=0.02,\n    n_estimators=10000,\n    num_leaves=80,\n    feature_fraction=0.90,\n    bagging_fraction=0.90,\n    bagging_freq=1,\n    reg_alpha=0.3,\n    reg_lambda=0.6,\n    random_state=SEED,\n    verbose=-1\n)\n\noof_lgb = np.zeros(len(X_lgb))\ntest_pred_folds_lgb = []\n\nfor fold, (tr_idx, va_idx) in enumerate(kf.split(X_lgb, y), 1):\n    X_tr, y_tr = X_lgb.iloc[tr_idx], y.iloc[tr_idx]\n    X_va, y_va = X_lgb.iloc[va_idx], y.iloc[va_idx]\n\n    model_lgb = lgb.LGBMRegressor(**lgb_params)\n    model_lgb.fit(\n        X_tr, y_tr,\n        eval_set=[(X_va, y_va)],\n        callbacks=[lgb.early_stopping(stopping_rounds=600, verbose=False)]\n    )\n\n    oof_lgb[va_idx] = model_lgb.predict(X_va, num_iteration=model_lgb.best_iteration_)\n    print(f\"[LightGBM Fold {fold}] RMSE: {rmse(y_va, oof_lgb[va_idx]):.5f}\")\n\n    test_pred_folds_lgb.append(model_lgb.predict(X_test_lgb, num_iteration=model_lgb.best_iteration_))\n\noof_lgb = clip01(oof_lgb)\ncv_rmse_lgb = rmse(y, oof_lgb)\nprint(f\"\\n[LightGBM] OOF CV RMSE: {cv_rmse_lgb:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T01:25:38.281145Z","iopub.execute_input":"2025-10-31T01:25:38.281382Z","iopub.status.idle":"2025-10-31T01:29:17.646580Z","shell.execute_reply.started":"2025-10-31T01:25:38.281366Z","shell.execute_reply":"2025-10-31T01:29:17.645640Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nRunning XGBoost CV...\")\n\nX_xgb = pd.get_dummies(X, columns=cat_cols, drop_first=False)\nX_test_xgb = pd.get_dummies(X_test, columns=cat_cols, drop_first=False)\nX_xgb, X_test_xgb = X_xgb.align(X_test_xgb, join=\"left\", axis=1, fill_value=0)\n\nxgb_params = dict(\n    n_estimators=12000,\n    learning_rate=0.028,\n    max_depth=6,\n    subsample=0.9,\n    colsample_bytree=0.9,\n    reg_alpha=0.1,\n    reg_lambda=1.0,\n    objective=\"reg:squarederror\",\n    random_state=SEED,\n    tree_method=\"hist\"\n)\n\noof_xgb = np.zeros(len(X_xgb))\ntest_pred_folds_xgb = []\n\nfor fold, (tr_idx, va_idx) in enumerate(kf.split(X_xgb, y), 1):\n    X_tr, y_tr = X_xgb.iloc[tr_idx], y.iloc[tr_idx]\n    X_va, y_va = X_xgb.iloc[va_idx], y.iloc[va_idx]\n\n    model_xgb = XGBRegressor(**xgb_params)\n    model_xgb.fit(\n        X_tr, y_tr,\n        eval_set=[(X_va, y_va)],\n        verbose=False,\n        early_stopping_rounds=800\n    )\n\n    oof_xgb[va_idx] = model_xgb.predict(X_va)\n    print(f\"[XGBoost Fold {fold}] RMSE: {rmse(y_va, oof_xgb[va_idx]):.5f}\")\n\n    test_pred_folds_xgb.append(model_xgb.predict(X_test_xgb))\n\noof_xgb = clip01(oof_xgb)\ncv_rmse_xgb = rmse(y, oof_xgb)\nprint(f\"\\n[XGBoost] OOF CV RMSE: {cv_rmse_xgb:.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T01:36:06.200989Z","iopub.execute_input":"2025-10-31T01:36:06.201228Z","iopub.status.idle":"2025-10-31T01:44:31.802762Z","shell.execute_reply.started":"2025-10-31T01:36:06.201213Z","shell.execute_reply":"2025-10-31T01:44:31.801995Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def blend2(a, b, w):          # 2-way linear\n    return clip01(w*a + (1-w)*b)\n\ndef blend3(a, b, c, w1, w2):  # 3-way linear\n    w3 = 1.0 - w1 - w2\n    return clip01(w1*a + w2*b + w3*c)\n\ndef rank_blend(preds_list, weights=None):  # rank-average (robust)\n    ranked = np.vstack([rankdata(p) for p in preds_list]).T\n    ranked = ranked / ranked.max(axis=0)\n    if weights is None:\n        return clip01(np.mean(ranked, axis=1))\n    else:\n        w = np.array(weights) / np.sum(weights)\n        return clip01(ranked @ w)\n\n# refined 2-way sweep (CB vs LGB)\nbest2, bestw2 = 1e9, 0.5\nfor w in np.arange(0.35, 0.71, 0.02):\n    sc = rmse(y, blend2(oof_cb, oof_lgb, w))\n    if sc < best2:\n        best2, bestw2 = sc, w\nprint(f\"[CB/LGB] Best 2-way: w={bestw2:.2f}, OOF={best2:.5f}\")\n\n# refined 3-way sweep around plausible region\nbest3, best_w = 1e9, (1/3, 1/3, 1/3)\nfor w_cb in np.arange(0.30, 0.61, 0.02):\n    for w_lgb in np.arange(0.30, 0.61, 0.02):\n        if w_cb + w_lgb >= 0.95:\n            continue\n        oof_bl3 = blend3(oof_cb, oof_lgb, oof_xgb, w_cb, w_lgb)\n        sc = rmse(y, oof_bl3)\n        if sc < best3:\n            best3, best_w = sc, (w_cb, w_lgb, 1.0 - w_cb - w_lgb)\nprint(f\"[CB/LGB/XGB] Best 3-way weights: {best_w} | OOF={best3:.5f}\")\n\n# stacking meta-model on OOF preds\nstack_train = np.vstack([oof_cb, oof_lgb, oof_xgb]).T\ntest_pred_cb   = clip01(np.mean(np.column_stack(test_pred_folds_cb),  axis=1))\ntest_pred_lgb  = clip01(np.mean(np.column_stack(test_pred_folds_lgb), axis=1))\ntest_pred_xgb  = clip01(np.mean(np.column_stack(test_pred_folds_xgb), axis=1))\nstack_test  = np.vstack([test_pred_cb, test_pred_lgb, test_pred_xgb]).T\n\nmeta = Ridge(alpha=1.0, random_state=SEED)\nmeta.fit(stack_train, y)\nmeta_oof  = clip01(meta.predict(stack_train))\nprint(f\"[Stacking Ridge] OOF RMSE: {rmse(y, meta_oof):.5f}\")\n\n# rank-based OOF\nrank_oof  = rank_blend([oof_cb, oof_lgb, oof_xgb], weights=[0.4,0.3,0.3])\nprint(f\"[RankBlend OOF] RMSE: {rmse(y, rank_oof):.5f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T01:45:21.767148Z","iopub.execute_input":"2025-10-31T01:45:21.767391Z","iopub.status.idle":"2025-10-31T01:45:22.592501Z","shell.execute_reply.started":"2025-10-31T01:45:21.767374Z","shell.execute_reply":"2025-10-31T01:45:22.591826Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred_blend2 = blend2(test_pred_cb, test_pred_lgb, bestw2)\nw_cb, w_lgb, w_xgb = best_w\npred_blend3 = blend3(test_pred_cb, test_pred_lgb, test_pred_xgb, w_cb, w_lgb)\npred_meta = clip01(meta.predict(stack_test))\npred_rank = rank_blend([test_pred_cb, test_pred_lgb, test_pred_xgb], weights=[0.4,0.3,0.3])\n\npd.DataFrame({\"id\": test[\"id\"], \"accident_risk\": test_pred_cb}).to_csv(\"submission_catboost_cv.csv\", index=False)\npd.DataFrame({\"id\": test[\"id\"], \"accident_risk\": test_pred_lgb}).to_csv(\"submission_lightgbm_cv.csv\", index=False)\npd.DataFrame({\"id\": test[\"id\"], \"accident_risk\": test_pred_xgb}).to_csv(\"submission_xgboost_cv.csv\", index=False)\npd.DataFrame({\"id\": test[\"id\"], \"accident_risk\": pred_blend2}).to_csv(\"submission_blend_cb_lgb.csv\", index=False)\npd.DataFrame({\"id\": test[\"id\"], \"accident_risk\": pred_blend3}).to_csv(\"submission_blend_cb_lgb_xgb.csv\", index=False)\npd.DataFrame({\"id\": test[\"id\"], \"accident_risk\": pred_meta}).to_csv(\"submission_meta_ridge.csv\", index=False)\npd.DataFrame({\"id\": test[\"id\"], \"accident_risk\": pred_rank}).to_csv(\"submission_rankblend.csv\", index=False)\n\nprint(\"\\nSaved:\")\nprint(\" - submission_catboost_cv.csv\")\nprint(\" - submission_lightgbm_cv.csv\")\nprint(\" - submission_xgboost_cv.csv\")\nprint(\" - submission_blend_cb_lgb.csv\")\nprint(\" - submission_blend_cb_lgb_xgb.csv\")\nprint(\" - submission_meta_ridge.csv\")\nprint(\" - submission_rankblend.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-31T01:45:42.260329Z","iopub.execute_input":"2025-10-31T01:45:42.260565Z","iopub.status.idle":"2025-10-31T01:45:43.753257Z","shell.execute_reply.started":"2025-10-31T01:45:42.260552Z","shell.execute_reply":"2025-10-31T01:45:43.752451Z"}},"outputs":[],"execution_count":null}]}